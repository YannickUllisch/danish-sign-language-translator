{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains all Functions and relevant code parts to extract keypoints from all videos inside of a given base Path\n",
    "\n",
    "### General important Information to be defined for running this can be seen and adjusted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Words\" contains the subset of words we make predictions for. \n",
    "words =  np.array(['hvad', 'ja', 'soed'])\n",
    "label_map = {label:num for num, label in enumerate(words)}\n",
    "\n",
    "# Base path leading to directory containing folders with videos for all signs defined in \"words\" array\n",
    "base_path = \"tegn_subset\"\n",
    "\n",
    "# Loading holistic model and drawing utilities (needed for Mediapipe solution)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediapipe Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):        \n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hand = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hand = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, left_hand, right_hand])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Processing, Keypoint Extraction and Exporting Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_process_export_logic(path, words, mp_holistic):\n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic_model:\n",
    "        # Looping through subset of words we choose to work with \n",
    "        for word in words:\n",
    "            dir_path = path + \"/\" + str(word) + \"/\"\n",
    "            # Loop through videos\n",
    "            for video in os.listdir(dir_path):\n",
    "                if video.endswith('.mp4'):\n",
    "                    # Importing videos and extracting frame amount\n",
    "                    vid_file = cv2.VideoCapture(dir_path + str(video))\n",
    "                    frame_amount = int(vid_file.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "                    # Loop through video frame sequence length\n",
    "                    for frame_nr in range(frame_amount):\n",
    "                        ret, frame = vid_file.read()\n",
    "                        image, results = process_image(frame, holistic_model)\n",
    "\n",
    "                        # Visualization logic \n",
    "                        #visualize_landmarks(image, results)\n",
    "                        #cv2.imshow('OpenCV Feed', image)\n",
    "                        \n",
    "                        # Exporting Keypoints\n",
    "                        keypoints = extract_keypoints(results)\n",
    "                        current_directory = os.path.join(base_path, str(word) + \"_data\", str(video.split(\".\")[0]))\n",
    "\n",
    "                        # Creates needed directory if it doesn't exist already\n",
    "                        if not (os.path.exists(current_directory)):\n",
    "                            os.makedirs(current_directory)\n",
    "                        np.save(os.path.join(current_directory, word) + str(frame_nr), keypoints)\n",
    "\n",
    "                        # Being able to quit video if necessary\n",
    "                        #if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "                        # break\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "        vid_file.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_process_export_logic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m video_process_export_logic(base_path, words, mp_holistic)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'video_process_export_logic' is not defined"
     ]
    }
   ],
   "source": [
    "video_process_export_logic(base_path, words, mp_holistic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m image, results \u001b[39m=\u001b[39m process_image(frame, holistic)\n\u001b[0;32m----> 7\u001b[0m draw_styled_landmarks(image, results)\n\u001b[1;32m      8\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mOpenCV Feed\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Break gracefully\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mdraw_styled_landmarks\u001b[0;34m(image, results)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_styled_landmarks\u001b[39m(image, results):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Draw face connections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mface_landmarks, mp_holistic\u001b[39m.\u001b[39;49mFACE_CONNECTIONS, \n\u001b[1;32m      4\u001b[0m                              mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m110\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \n\u001b[1;32m      5\u001b[0m                              mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m                              ) \n\u001b[1;32m      7\u001b[0m     \u001b[39m# Draw pose connections\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mpose_landmarks, mp_holistic\u001b[39m.\u001b[39mPOSE_CONNECTIONS,\n\u001b[1;32m      9\u001b[0m                              mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m22\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m), \n\u001b[1;32m     10\u001b[0m                              mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m44\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m                              ) \n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        image, results = process_image(frame, holistic)\n",
    "        draw_styled_landmarks(image, results)\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PRESENCE_THRESHOLD = 0.5\n",
    "_VISIBILITY_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "def plot_landmarks(landmark_list, connections=None, ):\n",
    "    if not landmark_list:\n",
    "        return\n",
    "    plotted_landmarks = {}\n",
    "    for idx, landmark in enumerate(landmark_list.landmark):\n",
    "        if (\n",
    "            landmark.HasField(\"visibility\")\n",
    "            and landmark.visibility < _VISIBILITY_THRESHOLD\n",
    "        ) or (\n",
    "            landmark.HasField(\"presence\") and landmark.presence < _PRESENCE_THRESHOLD\n",
    "        ):\n",
    "            continue\n",
    "        plotted_landmarks[idx] = (-landmark.z, landmark.x, -landmark.y)\n",
    "    if connections:\n",
    "        out_cn = []\n",
    "        num_landmarks = len(landmark_list.landmark)\n",
    "        # Draws the connections if the start and end landmarks are both visible.\n",
    "        for connection in connections:\n",
    "            start_idx = connection[0]\n",
    "            end_idx = connection[1]\n",
    "            if not (0 <= start_idx < num_landmarks and 0 <= end_idx < num_landmarks):\n",
    "                raise ValueError(\n",
    "                    f\"Landmark index is out of range. Invalid connection \"\n",
    "                    f\"from landmark #{start_idx} to landmark #{end_idx}.\"\n",
    "                )\n",
    "            if start_idx in plotted_landmarks and end_idx in plotted_landmarks:\n",
    "                landmark_pair = [\n",
    "                    plotted_landmarks[start_idx],\n",
    "                    plotted_landmarks[end_idx],\n",
    "                ]\n",
    "                out_cn.append(\n",
    "                    dict(\n",
    "                        xs=[landmark_pair[0][0], landmark_pair[1][0]],\n",
    "                        ys=[landmark_pair[0][1], landmark_pair[1][1]],\n",
    "                        zs=[landmark_pair[0][2], landmark_pair[1][2]],\n",
    "                    )\n",
    "                )\n",
    "        cn2 = {\"xs\": [], \"ys\": [], \"zs\": []}\n",
    "        for pair in out_cn:\n",
    "            for k in pair.keys():\n",
    "                cn2[k].append(pair[k][0])\n",
    "                cn2[k].append(pair[k][1])\n",
    "                cn2[k].append(None)\n",
    "\n",
    "    df = pd.DataFrame(plotted_landmarks).T.rename(columns={0: \"z\", 1: \"x\", 2: \"y\"})\n",
    "    df[\"lm\"] = df.index.map(lambda s: mp_holistic.PoseLandmark(s).name).values\n",
    "    fig = (\n",
    "        px.scatter_3d(df, x=\"z\", y=\"x\", z=\"y\", hover_name=\"lm\")\n",
    "        .update_traces(marker={\"color\": \"red\"})\n",
    "        .update_layout(\n",
    "            margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0},\n",
    "            scene={\"camera\": {\"eye\": {\"x\": 2.1, \"y\": 0, \"z\": 0}}},\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        [\n",
    "            go.Scatter3d(\n",
    "                x=cn2[\"xs\"],\n",
    "                y=cn2[\"ys\"],\n",
    "                z=cn2[\"zs\"],\n",
    "                mode=\"lines\",\n",
    "                line={\"color\": \"black\", \"width\": 5},\n",
    "                name=\"connections\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
