{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Used for normalization of data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Used for data interpolation\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy as sp\n",
    "\n",
    "# Used for low pass filtering\n",
    "from scipy.signal import butter,filtfilt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our used Subset of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing saved data and setting up Train and Test data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path, words, label_map):\n",
    "    # Keypoint_list_of_arrays is a python list containing \"video amount\" of NP arrays.\n",
    "    imp_data_list = []\n",
    "    labels = []\n",
    "    vid_frames = []\n",
    "    for word in words:\n",
    "        dir_path = path + \"/\" + str(word) + \"_data\" + \"/\"\n",
    "        for vid_folder in next(os.walk(dir_path))[1]:\n",
    "            # Finds number of .npy files in current vid_folder\n",
    "            frame_len = len([entry for entry in os.listdir(dir_path + str(vid_folder)) \n",
    "                            if entry.endswith('.npy') and os.path.isfile(os.path.join(dir_path + str(vid_folder), entry))])\n",
    "            vid_frames.append(frame_len)\n",
    "            tmp = []\n",
    "            for frame_num in range(frame_len):\n",
    "                imported_data = np.load(os.path.join(dir_path, vid_folder, word) + str(frame_num) + \".npy\")\n",
    "                tmp.append(imported_data)\n",
    "\n",
    "            tmp = np.array(tmp)\n",
    "\n",
    "            imp_data_list.append(tmp)\n",
    "            labels.append(label_map[word])\n",
    "\n",
    "    return imp_data_list, labels, vid_frames\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interpolating Keypoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting specific coordinates for right hand, left hand and pose from previously appended data.\n",
    "\n",
    "Meaning our first $33*4$ out of 258 values are for pose, the next $21*3$ are for left_hand and the last $21*3$ are for right_hand.\n",
    "We now want to seperate all coordinates and visibility values such that it is easy for us to access all specific coordinates \n",
    "for a single keypoint for all frames. \n",
    "\n",
    "We will then proceed to interpolate values for all coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As input array HAS to be of size (frame_amount, 258)\n",
    "def split_array(array_to_split):\n",
    "    # Splits total array into pose values and hand values \n",
    "    posearr, handarr = array_to_split[:, 0:132], array_to_split[:, 132::]\n",
    "\n",
    "    # Splititng handarr to seperate left hand from right hand values\n",
    "    splithandarr = np.split(handarr, 2, axis=1)\n",
    "    lhcoords, rhcoords = splithandarr[0], splithandarr[1]\n",
    "\n",
    "    # Extracting specific coordinates for both the left and right hand\n",
    "    rhxcoords, lhxcoords = rhcoords[:, 0::3], lhcoords[:, 0::3]\n",
    "    rhycoords, lhycoords  = rhcoords[:, 1::3], lhcoords[:, 1::3]\n",
    "    rhzcoords, lhzcoords = rhcoords[:, 2::3], lhcoords[:, 2::3]\n",
    "\n",
    "    # Splitting up coordinates and visibility values for pose\n",
    "    pxcoords, pycoords, pzcoords, pvis = posearr[:, 0::4], posearr[:, 1::4], posearr[:, 2::4], posearr[:, 3::4]\n",
    "\n",
    "    return pxcoords, pycoords, pzcoords, pvis, lhxcoords, lhycoords, lhzcoords, rhxcoords, rhycoords, rhzcoords\n",
    "\n",
    "# With this splitting it seems that every row (out of 48 total) now contains all x coordinates for one frame for BOTH hands\n",
    "# This means that to get all sequential x coordinates for one specific point we can take each column. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering for removal of outliars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://medium.com/analytics-vidhya/how-to-filter-noise-with-a-low-pass-filter-python-885223e5e9b7\n",
    "def butter_lowpass_filter(data):\n",
    "    fs = 20.0 # sample rate, Hz\n",
    "    cutoff = 2 # desired cutoff frequency of the filter, Hz, slightly higher than actual 1.2 Hz\n",
    "    order = 2 # sin wave can be approx represented as quadratic\n",
    "\n",
    "    normal_cutoff = cutoff / (0.5 * fs)\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "\n",
    "    #visualize_filtering(data, filtered_data)\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolating new keypoint using all sequential data for a single keypoint coordinate through all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_frames(keypoint_data, current_frames, max_frames):\n",
    "    # Calculate x and y values to be able to plot it later, furthermore also used for interpolation\n",
    "    x = range(0,current_frames)\n",
    "    y = keypoint_data\n",
    "\n",
    "    new_x = np.linspace(0, current_frames-1, max_frames, endpoint=False)\n",
    "    new_y = sp.interpolate.interp1d(x, y, kind='cubic')(new_x)\n",
    "    \n",
    "    #visualize_interpolation(x,y, new_x, new_y)\n",
    "    \n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_array_list, max_frames):\n",
    "    interpolated_list = []\n",
    "    for i in range(len(data_array_list)):\n",
    "        split_data = split_array(data_array_list[i])\n",
    "        tmp = []\n",
    "        for coords in range(len(split_data)):\n",
    "            coord_array = split_data[coords]\n",
    "            for col in range(coord_array.shape[1]):\n",
    "                normalized_data = preprocessing.normalize(coord_array[:, col].reshape(-1,1), axis=0).ravel()\n",
    "                filtered_data = butter_lowpass_filter(normalized_data)\n",
    "                interpolated_data = interpolate_frames(filtered_data,  filtered_data.shape[0], max_frames)\n",
    "                tmp.append(interpolated_data)\n",
    "\n",
    "        interpolated_list.append((np.array(tmp)).T)\n",
    "    return np.array(interpolated_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exporting Processed Data and Label array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_processed_data(export_path, processed_data, labels):\n",
    "    X = np.array(processed_data)\n",
    "    y = to_categorical(labels).astype(int)\n",
    "\n",
    "    np.save(str(export_path) + 'X_data', X)\n",
    "    np.save(str(export_path) + 'y_data', y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualization \n",
    "\n",
    "### Visualising low-pass filtering on specific keypoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filtering(unfiltered_data, filtered_data):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "                y = unfiltered_data,\n",
    "                line =  dict(shape =  'spline' ),\n",
    "                name = 'signal with noise'\n",
    "                ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "                y = filtered_data,\n",
    "                line =  dict(shape =  'spline' ),\n",
    "                name = 'filtered signal'\n",
    "                ))\n",
    "    fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Interpolation on specific keypoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(x, y, xnew, ynew):\n",
    "    # Plot the results\n",
    "    plt.figure()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(x, y, 'bo-')\n",
    "    plt.title('Using 1D Cubic Spline Interpolation')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(xnew, ynew, 'ro-')\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be5512a89907ef199886bb726a1c1fb2884526d07d9d0dc84c8b750dd2e562f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
